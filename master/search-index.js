var N = null;var searchIndex = {};
searchIndex["parquet"]={"doc":"Apache Parquet is a columnar storage format that provides efficient data compression and encoding schemes to improve performance of handling complex nested data structures. Parquet implements record-shredding and assembly algorithm described in the Dremel paper.","items":[[0,"errors","parquet","Common Parquet errors and macros.",N,N],[4,"ParquetError","parquet::errors","Set of errors that can be produced during different operations in Parquet.",N,N],[13,"General","","General Parquet error. Returned when code violates normal workflow of working with Parquet files.",0,N],[13,"NYI","","\"Not yet implemented\" Parquet error. Returned when functionality is not yet available.",0,N],[13,"EOF","","\"End of file\" Parquet error. Returned when IO related failures occur, e.g. when there are not enough bytes to decode.",0,N],[6,"Result","","A specialized `Result` for Parquet errors.",N,N],[11,"fmt","","",0,[[["self"],["formatter"]],["result"]]],[11,"eq","","",0,[[["self"],["parqueterror"]],["bool"]]],[11,"ne","","",0,[[["self"],["parqueterror"]],["bool"]]],[11,"fmt","","",0,[[["self"],["formatter"]],["result"]]],[11,"description","","",0,[[["self"]],["str"]]],[11,"cause","","",0,[[["self"]],["option",["error"]]]],[11,"from","","",0,[[["error"]],["parqueterror"]]],[11,"from","","",0,[[["error"]],["parqueterror"]]],[11,"from","","",0,[[["error"]],["parqueterror"]]],[11,"from","","",0,[[["borrowmuterror"]],["parqueterror"]]],[0,"basic","parquet","Contains Rust mappings for Thrift definition. Refer to `parquet.thrift` file to see raw definitions.",N,N],[4,"Type","parquet::basic","Types supported by Parquet. These physical types are intended to be used in combination with the encodings to control the on disk storage format. For example INT16 is not included as a type since a good encoding of INT32 would handle this.",N,N],[13,"BOOLEAN","","",1,N],[13,"INT32","","",1,N],[13,"INT64","","",1,N],[13,"INT96","","",1,N],[13,"FLOAT","","",1,N],[13,"DOUBLE","","",1,N],[13,"BYTE_ARRAY","","",1,N],[13,"FIXED_LEN_BYTE_ARRAY","","",1,N],[4,"LogicalType","","Common types (logical types) used by frameworks when using Parquet. This helps map between types in those frameworks to the base types in Parquet. This is only metadata and not needed to read or write the data.",N,N],[13,"NONE","","",2,N],[13,"UTF8","","A BYTE_ARRAY actually contains UTF8 encoded chars.",2,N],[13,"MAP","","A map is converted as an optional field containing a repeated key/value pair.",2,N],[13,"MAP_KEY_VALUE","","A key/value pair is converted into a group of two fields.",2,N],[13,"LIST","","A list is converted into an optional field containing a repeated field for its values.",2,N],[13,"ENUM","","An enum is converted into a binary field",2,N],[13,"DECIMAL","","A decimal value. This may be used to annotate binary or fixed primitive types. The underlying byte array stores the unscaled value encoded as two's complement using big-endian byte order (the most significant byte is the zeroth element).",2,N],[13,"DATE","","A date stored as days since Unix epoch, encoded as the INT32 physical type.",2,N],[13,"TIME_MILLIS","","The total number of milliseconds since midnight. The value is stored as an INT32 physical type.",2,N],[13,"TIME_MICROS","","The total number of microseconds since midnight. The value is stored as an INT64 physical type.",2,N],[13,"TIMESTAMP_MILLIS","","Date and time recorded as milliseconds since the Unix epoch. Recorded as a physical type of INT64.",2,N],[13,"TIMESTAMP_MICROS","","Date and time recorded as microseconds since the Unix epoch. The value is stored as an INT64 physical type.",2,N],[13,"UINT_8","","An unsigned 8 bit integer value stored as INT32 physical type.",2,N],[13,"UINT_16","","An unsigned 16 bit integer value stored as INT32 physical type.",2,N],[13,"UINT_32","","An unsigned 32 bit integer value stored as INT32 physical type.",2,N],[13,"UINT_64","","An unsigned 64 bit integer value stored as INT64 physical type.",2,N],[13,"INT_8","","A signed 8 bit integer value stored as INT32 physical type.",2,N],[13,"INT_16","","A signed 16 bit integer value stored as INT32 physical type.",2,N],[13,"INT_32","","A signed 32 bit integer value stored as INT32 physical type.",2,N],[13,"INT_64","","A signed 64 bit integer value stored as INT64 physical type.",2,N],[13,"JSON","","A JSON document embedded within a single UTF8 column.",2,N],[13,"BSON","","A BSON document embedded within a single BINARY column.",2,N],[13,"INTERVAL","","An interval of time.",2,N],[4,"Repetition","","Representation of field types in schema.",N,N],[13,"REQUIRED","","Field is required (can not be null) and each record has exactly 1 value.",3,N],[13,"OPTIONAL","","Field is optional (can be null) and each record has 0 or 1 values.",3,N],[13,"REPEATED","","Field is repeated and can contain 0 or more values.",3,N],[4,"Encoding","","Encodings supported by Parquet. Not all encodings are valid for all types. These enums are also used to specify the encoding of definition and repetition levels.",N,N],[13,"PLAIN","","Default byte encoding. - BOOLEAN - 1 bit per value, 0 is false; 1 is true. - INT32 - 4 bytes per value, stored as little-endian. - INT64 - 8 bytes per value, stored as little-endian. - FLOAT - 4 bytes per value, stored as little-endian. - DOUBLE - 8 bytes per value, stored as little-endian. - BYTE_ARRAY - 4 byte length stored as little endian, followed by bytes. - FIXED_LEN_BYTE_ARRAY - just the bytes are stored.",4,N],[13,"PLAIN_DICTIONARY","","Deprecated dictionary encoding.",4,N],[13,"RLE","","Group packed run length encoding.",4,N],[13,"BIT_PACKED","","Bit packed encoding.",4,N],[13,"DELTA_BINARY_PACKED","","Delta encoding for integers, either INT32 or INT64.",4,N],[13,"DELTA_LENGTH_BYTE_ARRAY","","Encoding for byte arrays to separate the length values and the data.",4,N],[13,"DELTA_BYTE_ARRAY","","Incremental encoding for byte arrays.",4,N],[13,"RLE_DICTIONARY","","Dictionary encoding.",4,N],[4,"Compression","","Supported compression algorithms.",N,N],[13,"UNCOMPRESSED","","",5,N],[13,"SNAPPY","","",5,N],[13,"GZIP","","",5,N],[13,"LZO","","",5,N],[13,"BROTLI","","",5,N],[13,"LZ4","","",5,N],[13,"ZSTD","","",5,N],[4,"PageType","","Available data pages for Parquet file format. Note that some of the page types may not be supported.",N,N],[13,"DATA_PAGE","","",6,N],[13,"INDEX_PAGE","","",6,N],[13,"DICTIONARY_PAGE","","",6,N],[13,"DATA_PAGE_V2","","",6,N],[4,"SortOrder","","Sort order for page and column statistics.",N,N],[13,"SIGNED","","Signed (either value or legacy byte-wise) comparison.",7,N],[13,"UNSIGNED","","Unsigned (depending on physical type either value or byte-wise) comparison.",7,N],[13,"UNDEFINED","","Comparison is undefined.",7,N],[4,"ColumnOrder","","Column order that specifies what method was used to aggregate min/max values for statistics.",N,N],[13,"TYPE_DEFINED_ORDER","","Column uses the order defined by its logical or physical type (if there is no logical type), parquet-format 2.4.0+.",8,N],[13,"UNDEFINED","","Undefined column order, means legacy behaviour before parquet-format 2.4.0. Sort order is always SIGNED.",8,N],[11,"fmt","","",1,[[["self"],["formatter"]],["result"]]],[11,"clone","","",1,[[["self"]],["type"]]],[11,"eq","","",1,[[["self"],["type"]],["bool"]]],[11,"fmt","","",2,[[["self"],["formatter"]],["result"]]],[11,"clone","","",2,[[["self"]],["logicaltype"]]],[11,"eq","","",2,[[["self"],["logicaltype"]],["bool"]]],[11,"fmt","","",3,[[["self"],["formatter"]],["result"]]],[11,"clone","","",3,[[["self"]],["repetition"]]],[11,"eq","","",3,[[["self"],["repetition"]],["bool"]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result"]]],[11,"clone","","",4,[[["self"]],["encoding"]]],[11,"eq","","",4,[[["self"],["encoding"]],["bool"]]],[11,"hash","","",4,N],[11,"fmt","","",5,[[["self"],["formatter"]],["result"]]],[11,"clone","","",5,[[["self"]],["compression"]]],[11,"eq","","",5,[[["self"],["compression"]],["bool"]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result"]]],[11,"clone","","",6,[[["self"]],["pagetype"]]],[11,"eq","","",6,[[["self"],["pagetype"]],["bool"]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result"]]],[11,"clone","","",7,[[["self"]],["sortorder"]]],[11,"eq","","",7,[[["self"],["sortorder"]],["bool"]]],[11,"fmt","","",8,[[["self"],["formatter"]],["result"]]],[11,"clone","","",8,[[["self"]],["columnorder"]]],[11,"eq","","",8,[[["self"],["columnorder"]],["bool"]]],[11,"ne","","",8,[[["self"],["columnorder"]],["bool"]]],[11,"get_sort_order","","Returns sort order for a physical/logical type.",8,[[["logicaltype"],["type"]],["sortorder"]]],[11,"sort_order","","Returns sort order associated with this column order.",8,[[["self"]],["sortorder"]]],[11,"fmt","","",1,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",2,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",3,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",5,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",8,[[["self"],["formatter"]],["result"]]],[11,"from","","",1,[[["type"]],["self"]]],[11,"from","","",2,[[["option",["convertedtype"]]],["self"]]],[11,"from","","",3,[[["fieldrepetitiontype"]],["self"]]],[11,"from","","",4,[[["encoding"]],["self"]]],[11,"from","","",5,[[["compressioncodec"]],["self"]]],[11,"from","","",6,[[["pagetype"]],["self"]]],[11,"from_str","","",3,[[["str"]],["result"]]],[11,"from_str","","",1,[[["str"]],["result"]]],[11,"from_str","","",2,[[["str"]],["result"]]],[0,"data_type","parquet","Data types that connect Parquet physical types with their Rust-specific representations.",N,N],[3,"Int96","parquet::data_type","Rust representation for logical type INT96, value is backed by an array of `u32`. The type only takes 12 bytes, without extra padding.",N,N],[3,"ByteArray","","Rust representation for BYTE_ARRAY and FIXED_LEN_BYTE_ARRAY Parquet physical types. Value is backed by a byte buffer.",N,N],[3,"BoolType","","",N,N],[3,"Int32Type","","",N,N],[3,"Int64Type","","",N,N],[3,"Int96Type","","",N,N],[3,"FloatType","","",N,N],[3,"DoubleType","","",N,N],[3,"ByteArrayType","","",N,N],[3,"FixedLenByteArrayType","","",N,N],[4,"Decimal","","Rust representation for Decimal values.",N,N],[13,"Int32","","Decimal backed by `i32`.",9,N],[12,"value","parquet::data_type::Decimal","",9,N],[12,"precision","","",9,N],[12,"scale","","",9,N],[13,"Int64","parquet::data_type","Decimal backed by `i64`.",9,N],[12,"value","parquet::data_type::Decimal","",9,N],[12,"precision","","",9,N],[12,"scale","","",9,N],[13,"Bytes","parquet::data_type","Decimal backed by byte array.",9,N],[12,"value","parquet::data_type::Decimal","",9,N],[12,"precision","","",9,N],[12,"scale","","",9,N],[8,"AsBytes","parquet::data_type","Converts an instance of data type to a slice of bytes as `u8`.",N,N],[10,"as_bytes","","Returns slice of bytes for this data type.",10,N],[8,"DataType","","Contains the Parquet physical type information as well as the Rust primitive type presentation.",N,N],[16,"T","","",11,N],[10,"get_physical_type","","Returns Parquet physical type.",11,[[],["type"]]],[10,"get_type_size","","Returns size in bytes for Rust representation of the physical type.",11,[[],["usize"]]],[11,"clone","","",12,[[["self"]],["int96"]]],[11,"fmt","","",12,[[["self"],["formatter"]],["result"]]],[11,"new","","Creates new INT96 type struct with no data set.",12,[[],["self"]]],[11,"data","","Returns underlying data as slice of [`u32`].",12,N],[11,"set_data","","Sets data for this INT96 type.",12,[[["self"],["u32"],["u32"],["u32"]]]],[11,"default","","",12,[[],["self"]]],[11,"eq","","",12,[[["self"],["int96"]],["bool"]]],[11,"from","","",12,[[["vec",["u32"]]],["self"]]],[11,"clone","","",13,[[["self"]],["bytearray"]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result"]]],[11,"new","","Creates new byte array with no data set.",13,[[],["self"]]],[11,"len","","Gets length of the underlying byte buffer.",13,[[["self"]],["usize"]]],[11,"data","","Returns slice of data.",13,N],[11,"set_data","","Set data from another byte buffer.",13,[[["self"],["bytebufferptr"]]]],[11,"slice","","Returns `ByteArray` instance with slice of values for a data.",13,[[["self"],["usize"],["usize"]],["self"]]],[11,"from","","",13,[[["vec",["u8"]]],["bytearray"]]],[11,"from","","",13,[[["str"]],["bytearray"]]],[11,"from","","",13,[[["bytebufferptr"]],["bytearray"]]],[11,"from","","",13,[[["bytebuffer"]],["bytearray"]]],[11,"default","","",13,[[],["self"]]],[11,"eq","","",13,[[["self"],["bytearray"]],["bool"]]],[11,"clone","","",9,[[["self"]],["decimal"]]],[11,"fmt","","",9,[[["self"],["formatter"]],["result"]]],[11,"from_i32","","Creates new decimal value from `i32`.",9,[[["i32"],["i32"],["i32"]],["self"]]],[11,"from_i64","","Creates new decimal value from `i64`.",9,[[["i64"],["i32"],["i32"]],["self"]]],[11,"from_bytes","","Creates new decimal value from `ByteArray`.",9,[[["bytearray"],["i32"],["i32"]],["self"]]],[11,"data","","Returns bytes of unscaled value.",9,N],[11,"precision","","Returns decimal precision.",9,[[["self"]],["i32"]]],[11,"scale","","Returns decimal scale.",9,[[["self"]],["i32"]]],[11,"default","","",9,[[],["self"]]],[11,"eq","","",9,[[["self"],["decimal"]],["bool"]]],[11,"as_bytes","","",12,N],[11,"as_bytes","","",13,N],[11,"as_bytes","","",9,N],[11,"get_physical_type","","",14,[[],["type"]]],[11,"get_type_size","","",14,[[],["usize"]]],[11,"get_physical_type","","",15,[[],["type"]]],[11,"get_type_size","","",15,[[],["usize"]]],[11,"get_physical_type","","",16,[[],["type"]]],[11,"get_type_size","","",16,[[],["usize"]]],[11,"get_physical_type","","",17,[[],["type"]]],[11,"get_type_size","","",17,[[],["usize"]]],[11,"get_physical_type","","",18,[[],["type"]]],[11,"get_type_size","","",18,[[],["usize"]]],[11,"get_physical_type","","",19,[[],["type"]]],[11,"get_type_size","","",19,[[],["usize"]]],[11,"get_physical_type","","",20,[[],["type"]]],[11,"get_type_size","","",20,[[],["usize"]]],[11,"get_physical_type","","",21,[[],["type"]]],[11,"get_type_size","","",21,[[],["usize"]]],[0,"memory","parquet","Utility methods and structs for working with memory.",N,N],[3,"MemTracker","parquet::memory","Struct to track memory usage information.",N,N],[3,"Buffer","","A resize-able buffer class with generic member, with optional memory tracker.",N,N],[3,"BufferPtr","","An representation of a slice on a reference-counting and read-only byte array. Sub-slices can be further created from this. The byte array will be released when all slices are dropped.",N,N],[6,"MemTrackerPtr","","Reference counted pointer for [`MemTracker`].",N,N],[6,"WeakMemTrackerPtr","","Non-owning reference for [`MemTracker`].",N,N],[6,"ByteBuffer","","Type alias for [`Buffer`].",N,N],[6,"ByteBufferPtr","","Type alias for [`BufferPtr`].",N,N],[0,"encoding","parquet","Contains all supported encoders for Parquet.",N,N],[3,"PlainEncoder","parquet::encoding","Plain encoding that supports all types. Values are encoded back to back. The plain encoding is used whenever a more efficient encoding can not be used. It stores the data in the following format: - BOOLEAN - 1 bit per value, 0 is false; 1 is true. - INT32 - 4 bytes per value, stored as little-endian. - INT64 - 8 bytes per value, stored as little-endian. - FLOAT - 4 bytes per value, stored as IEEE little-endian. - DOUBLE - 8 bytes per value, stored as IEEE little-endian. - BYTE_ARRAY - 4 byte length stored as little endian, followed by bytes. - FIXED_LEN_BYTE_ARRAY - just the bytes are stored.",N,N],[3,"DictEncoder","","Dictionary encoder. The dictionary encoding builds a dictionary of values encountered in a given column. The dictionary page is written first, before the data pages of the column chunk.",N,N],[3,"RleValueEncoder","","RLE/Bit-Packing hybrid encoding for values. Currently is used only for data pages v2 and supports boolean types.",N,N],[3,"DeltaBitPackEncoder","","Delta bit packed encoder. Consists of a header followed by blocks of delta encoded values binary packed.",N,N],[3,"DeltaLengthByteArrayEncoder","","Encoding for byte arrays to separate the length values and the data. The lengths are encoded using DELTA_BINARY_PACKED encoding, data is stored as raw bytes.",N,N],[3,"DeltaByteArrayEncoder","","Encoding for byte arrays, prefix lengths are encoded using DELTA_BINARY_PACKED encoding, followed by suffixes with DELTA_LENGTH_BYTE_ARRAY encoding.",N,N],[5,"get_encoder","","Gets a encoder for the particular data type `T` and encoding `encoding`. Memory usage for the encoder instance is tracked by `mem_tracker`.",N,[[["columndescptr"],["encoding"],["memtrackerptr"]],["result",["box"]]]],[8,"Encoder","","An Parquet encoder for the data type `T`.",N,N],[10,"put","","Encodes data from `values`.",22,N],[10,"encoding","","Returns the encoding type of this encoder.",22,[[["self"]],["encoding"]]],[10,"estimated_data_encoded_size","","Returns an estimate of the encoded data, in bytes. Method call must be O(1).",22,[[["self"]],["usize"]]],[10,"flush_buffer","","Flushes the underlying byte buffer that's being processed by this encoder, and return the immutable copy of it. This will also reset the internal state.",22,[[["self"]],["result",["bytebufferptr"]]]],[0,"decoding","parquet","Contains all supported decoders for Parquet.",N,N],[3,"PlainDecoder","parquet::decoding","Plain decoding that supports all types. Values are encoded back to back. For native types, data is encoded as little endian. Floating point types are encoded in IEEE. See `PlainDecoder` for more information.",N,N],[3,"DictDecoder","","Dictionary decoder. The dictionary encoding builds a dictionary of values encountered in a given column. The dictionary is be stored in a dictionary page per column chunk. See `DictEncoder` for more information.",N,N],[3,"RleValueDecoder","","RLE/Bit-Packing hybrid decoding for values. Currently is used only for data pages v2 and supports boolean types. See `RleValueEncoder` for more information.",N,N],[3,"DeltaBitPackDecoder","","Delta binary packed decoder. Supports INT32 and INT64 types. See `DeltaBitPackEncoder` for more information.",N,N],[3,"DeltaLengthByteArrayDecoder","","Delta length byte array decoder. Only applied to byte arrays to separate the length values and the data, the lengths are encoded using DELTA_BINARY_PACKED encoding. See `DeltaLengthByteArrayEncoder` for more information.",N,N],[3,"DeltaByteArrayDecoder","","Delta byte array decoder. Prefix lengths are encoded using `DELTA_BINARY_PACKED` encoding, Suffixes are stored using `DELTA_LENGTH_BYTE_ARRAY` encoding. See `DeltaByteArrayEncoder` for more information.",N,N],[5,"get_decoder","","Gets a decoder for the column descriptor `descr` and encoding type `encoding`.",N,[[["columndescptr"],["encoding"]],["result",["box"]]]],[8,"Decoder","","A Parquet decoder for the data type `T`.",N,N],[10,"set_data","","Sets the data to decode to be `data`, which should contain `num_values` of values to decode.",23,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[10,"get","","Consumes values from this decoder and write the results to `buffer`. This will try to fill up `buffer`.",23,N],[10,"values_left","","Returns the number of values left in this decoder stream.",23,[[["self"]],["usize"]]],[10,"encoding","","Returns the encoding for this decoder.",23,[[["self"]],["encoding"]]],[11,"fmt","parquet::memory","",24,[[["self"],["formatter"]],["result"]]],[11,"new","","Creates new memory tracker.",24,[[],["memtracker"]]],[11,"memory_usage","","Returns the current memory consumption, in bytes.",24,[[["self"]],["i64"]]],[11,"max_memory_usage","","Returns the maximum memory consumption so far, in bytes.",24,[[["self"]],["i64"]]],[11,"alloc","","Adds `num_bytes` to the memory consumption tracked by this memory tracker.",24,[[["self"],["i64"]]]],[11,"new","","Creates new empty buffer.",25,[[],["self"]]],[11,"with_mem_tracker","","Adds [`MemTracker`] for this buffer.",25,[[["self"],["memtrackerptr"]],["self"]]],[11,"data","","Returns slice of data in this buffer.",25,N],[11,"set_data","","Sets data for this buffer.",25,[[["self"],["vec"]]]],[11,"resize","","Resizes underlying data in place to a new length `new_size`.",25,[[["self"],["usize"],["t"]]]],[11,"clear","","Clears underlying data.",25,[[["self"]]]],[11,"reserve","","Reserves capacity `additional_capacity` for underlying data vector.",25,[[["self"],["usize"]]]],[11,"consume","","Returns [`BufferPtr`] with buffer data. Buffer data is reset.",25,[[["self"]],["bufferptr"]]],[11,"push","","Adds `value` to the buffer.",25,[[["self"],["t"]]]],[11,"capacity","","Returns current capacity for the buffer.",25,[[["self"]],["usize"]]],[11,"size","","Returns current size for the buffer.",25,[[["self"]],["usize"]]],[11,"is_mem_tracked","","Returns `true` if memory tracker is added to buffer, `false` otherwise.",25,[[["self"]],["bool"]]],[11,"mem_tracker","","Returns memory tracker associated with this buffer. This may panic, if memory tracker is not set, use method above to check if memory tracker is available.",25,[[["self"]],["memtrackerptr"]]],[11,"index","","",25,[[["self"],["usize"]],["t"]]],[11,"index_mut","","",25,[[["self"],["usize"]],["t"]]],[11,"write","","",25,N],[11,"flush","","",25,[[["self"]],["ioresult"]]],[11,"as_ref","","",25,N],[11,"drop","","",25,[[["self"]]]],[11,"clone","","",26,[[["self"]],["bufferptr"]]],[11,"fmt","","",26,[[["self"],["formatter"]],["result"]]],[11,"new","","Creates new buffer from a vector.",26,[[["vec"]],["self"]]],[11,"data","","Returns slice of data in this buffer.",26,N],[11,"with_range","","Updates this buffer with new `start` position and length `len`.",26,[[["self"],["usize"],["usize"]],["self"]]],[11,"with_mem_tracker","","Adds memory tracker to this buffer.",26,[[["self"],["memtrackerptr"]],["self"]]],[11,"start","","Returns start position of this buffer.",26,[[["self"]],["usize"]]],[11,"len","","Returns length of this buffer",26,[[["self"]],["usize"]]],[11,"is_mem_tracked","","Returns `true` if this buffer has memory tracker, `false` otherwise.",26,[[["self"]],["bool"]]],[11,"all","","Returns a shallow copy of the buffer. Reference counted pointer to the data is copied.",26,[[["self"]],["bufferptr"]]],[11,"start_from","","Returns a shallow copy of the buffer that starts with `start` position.",26,[[["self"],["usize"]],["bufferptr"]]],[11,"range","","Returns a shallow copy that is a range slice within this buffer.",26,[[["self"],["usize"],["usize"]],["bufferptr"]]],[11,"index","","",26,[[["self"],["usize"]],["t"]]],[11,"fmt","","",26,[[["self"],["formatter"]],["fmtresult"]]],[11,"drop","","",26,[[["self"]]]],[11,"as_ref","","",26,N],[11,"new","parquet::encoding","Creates new plain encoder.",27,[[["columndescptr"],["memtrackerptr"],["vec",["u8"]]],["self"]]],[11,"put","","",27,N],[11,"encoding","","",27,[[["self"]],["encoding"]]],[11,"estimated_data_encoded_size","","",27,[[["self"]],["usize"]]],[11,"flush_buffer","","",27,[[["self"]],["result",["bytebufferptr"]]]],[11,"put","","",27,N],[11,"put","","",27,N],[11,"put","","",27,N],[11,"put","","",27,N],[11,"new","","Creates new dictionary encoder.",28,[[["columndescptr"],["memtrackerptr"]],["self"]]],[11,"num_entries","","Returns number of unique values (keys) in the dictionary.",28,[[["self"]],["usize"]]],[11,"dict_encoded_size","","Returns size of unique values (keys) in the dictionary, in bytes.",28,[[["self"]],["usize"]]],[11,"write_dict","","Writes out the dictionary values with PLAIN encoding in a byte buffer, and return the result.",28,[[["self"]],["result",["bytebufferptr"]]]],[11,"write_indices","","Writes out the dictionary values with RLE encoding in a byte buffer, and return the result.",28,[[["self"]],["result",["bytebufferptr"]]]],[11,"put","","",28,N],[11,"encoding","","",28,[[["self"]],["encoding"]]],[11,"estimated_data_encoded_size","","",28,[[["self"]],["usize"]]],[11,"flush_buffer","","",28,[[["self"]],["result",["bytebufferptr"]]]],[11,"new","","Creates new rle value encoder.",29,[[],["self"]]],[11,"put","","",29,N],[11,"encoding","","",29,[[["self"]],["encoding"]]],[11,"estimated_data_encoded_size","","",29,[[["self"]],["usize"]]],[11,"flush_buffer","","",29,[[["self"]],["result",["bytebufferptr"]]]],[11,"put","","",29,N],[11,"flush_buffer","","",29,[[["self"]],["result",["bytebufferptr"]]]],[11,"new","","Creates new delta bit packed encoder.",30,[[],["self"]]],[11,"put","","",30,N],[11,"encoding","","",30,[[["self"]],["encoding"]]],[11,"estimated_data_encoded_size","","",30,[[["self"]],["usize"]]],[11,"flush_buffer","","",30,[[["self"]],["result",["bytebufferptr"]]]],[11,"new","","Creates new delta length byte array encoder.",31,[[],["self"]]],[11,"put","","",31,N],[11,"encoding","","",31,[[["self"]],["encoding"]]],[11,"estimated_data_encoded_size","","",31,[[["self"]],["usize"]]],[11,"flush_buffer","","",31,[[["self"]],["result",["bytebufferptr"]]]],[11,"put","","",31,N],[11,"flush_buffer","","",31,[[["self"]],["result",["bytebufferptr"]]]],[11,"new","","Creates new delta byte array encoder.",32,[[],["self"]]],[11,"put","","",32,N],[11,"encoding","","",32,[[["self"]],["encoding"]]],[11,"estimated_data_encoded_size","","",32,[[["self"]],["usize"]]],[11,"flush_buffer","","",32,[[["self"]],["result",["bytebufferptr"]]]],[11,"put","","",32,N],[11,"flush_buffer","","",32,[[["self"]],["result",["bytebufferptr"]]]],[11,"put","","",32,N],[11,"flush_buffer","","",32,[[["self"]],["result",["bytebufferptr"]]]],[11,"new","parquet::decoding","Creates new plain decoder.",33,[[["i32"]],["self"]]],[11,"set_data","","",33,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"values_left","","",33,[[["self"]],["usize"]]],[11,"encoding","","",33,[[["self"]],["encoding"]]],[11,"get","","",33,N],[11,"get","","",33,N],[11,"set_data","","",33,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"get","","",33,N],[11,"get","","",33,N],[11,"get","","",33,N],[11,"new","","Creates new dictionary decoder.",34,[[],["self"]]],[11,"set_dict","","Decodes and sets values for dictionary using `decoder` decoder.",34,[[["self"],["box",["decoder"]]],["result"]]],[11,"set_data","","",34,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"get","","",34,N],[11,"values_left","","Number of values left in this decoder stream",34,[[["self"]],["usize"]]],[11,"encoding","","",34,[[["self"]],["encoding"]]],[11,"new","","",35,[[],["self"]]],[11,"set_data","","",35,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"values_left","","",35,[[["self"]],["usize"]]],[11,"encoding","","",35,[[["self"]],["encoding"]]],[11,"get","","",35,N],[11,"set_data","","",35,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"new","","Creates new delta bit packed decoder.",36,[[],["self"]]],[11,"get_offset","","Returns underlying bit reader offset.",36,[[["self"]],["usize"]]],[11,"set_data","","",36,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"get","","",36,N],[11,"values_left","","",36,[[["self"]],["usize"]]],[11,"encoding","","",36,[[["self"]],["encoding"]]],[11,"new","","Creates new delta length byte array decoder.",37,[[],["self"]]],[11,"set_data","","",37,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"get","","",37,N],[11,"values_left","","",37,[[["self"]],["usize"]]],[11,"encoding","","",37,[[["self"]],["encoding"]]],[11,"set_data","","",37,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"get","","",37,N],[11,"new","","Creates new delta byte array decoder.",38,[[],["self"]]],[11,"set_data","","",38,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"get","","",38,N],[11,"values_left","","",38,[[["self"]],["usize"]]],[11,"encoding","","",38,[[["self"]],["encoding"]]],[11,"set_data","","",38,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"get","","",38,N],[11,"set_data","","",38,[[["self"],["bytebufferptr"],["usize"]],["result"]]],[11,"get","","",38,N],[0,"compression","parquet","Contains codec interface and supported codec implementations.",N,N],[3,"SnappyCodec","parquet::compression","Codec for Snappy compression format.",N,N],[3,"GZipCodec","","Codec for GZIP compression algorithm.",N,N],[3,"BrotliCodec","","Codec for Brotli compression algorithm.",N,N],[3,"LZ4Codec","","Codec for LZ4 compression algorithm.",N,N],[3,"ZSTDCodec","","Codec for Zstandard compression algorithm.",N,N],[5,"create_codec","","Given the compression type `codec`, returns a codec used to compress and decompress bytes for the compression type. This returns `None` if the codec type is `UNCOMPRESSED`.",N,[[["codectype"]],["result",["option"]]]],[8,"Codec","","Parquet compression codec interface.",N,N],[10,"compress","","Compresses data stored in slice `input_buf` and writes the compressed result to `output_buf`. Note that you'll need to call `clear()` before reusing the same `output_buf` across different `compress` calls.",39,N],[10,"decompress","","Decompresses data stored in slice `input_buf` and writes output to `output_buf`. Returns the total number of bytes written.",39,N],[11,"decompress","","",40,N],[11,"compress","","",40,N],[11,"decompress","","",41,N],[11,"compress","","",41,N],[11,"decompress","","",42,N],[11,"compress","","",42,N],[11,"decompress","","",43,N],[11,"compress","","",43,N],[11,"decompress","","",44,N],[11,"compress","","",44,N],[0,"column","parquet","Low level column reader API.",N,N],[0,"page","parquet::column","Contains Parquet Page definitions and page reader interface.",N,N],[4,"Page","parquet::column::page","Parquet Page definition.",N,N],[13,"DataPage","","",45,N],[12,"buf","parquet::column::page::Page","",45,N],[12,"num_values","","",45,N],[12,"encoding","","",45,N],[12,"def_level_encoding","","",45,N],[12,"rep_level_encoding","","",45,N],[12,"statistics","","",45,N],[13,"DataPageV2","parquet::column::page","",45,N],[12,"buf","parquet::column::page::Page","",45,N],[12,"num_values","","",45,N],[12,"encoding","","",45,N],[12,"num_nulls","","",45,N],[12,"num_rows","","",45,N],[12,"def_levels_byte_len","","",45,N],[12,"rep_levels_byte_len","","",45,N],[12,"is_compressed","","",45,N],[12,"statistics","","",45,N],[13,"DictionaryPage","parquet::column::page","",45,N],[12,"buf","parquet::column::page::Page","",45,N],[12,"num_values","","",45,N],[12,"encoding","","",45,N],[12,"is_sorted","","",45,N],[8,"PageReader","parquet::column::page","API for reading pages from a column chunk. This offers a iterator like API to get the next page.",N,N],[10,"get_next_page","","Gets the next page in the column chunk associated with this reader. Returns `None` if there are no pages left.",46,[[["self"]],["result",["option"]]]],[11,"page_type","","Returns `PageType` for this page.",45,[[["self"]],["pagetype"]]],[11,"buffer","","Returns internal byte buffer reference for this page.",45,[[["self"]],["bytebufferptr"]]],[11,"num_values","","Returns number of values in this page.",45,[[["self"]],["u32"]]],[11,"encoding","","Returns this page `Encoding`.",45,[[["self"]],["encoding"]]],[11,"statistics","","Returns optional `Statistics`.",45,[[["self"]],["option",["statistics"]]]],[0,"reader","parquet::column","Contains column reader API.",N,N],[3,"ColumnReaderImpl","parquet::column::reader","Typed value reader for a particular primitive column.",N,N],[4,"ColumnReader","","Column reader for a Parquet type.",N,N],[13,"BoolColumnReader","","",47,N],[13,"Int32ColumnReader","","",47,N],[13,"Int64ColumnReader","","",47,N],[13,"Int96ColumnReader","","",47,N],[13,"FloatColumnReader","","",47,N],[13,"DoubleColumnReader","","",47,N],[13,"ByteArrayColumnReader","","",47,N],[13,"FixedLenByteArrayColumnReader","","",47,N],[5,"get_column_reader","","Gets a specific column reader corresponding to column descriptor `col_descr`. The column reader will read from pages in `col_page_reader`.",N,[[["columndescptr"],["box",["pagereader"]]],["columnreader"]]],[5,"get_typed_column_reader","","Gets a typed column reader for the specific type `T`, by \"up-casting\" `col_reader` of non-generic type to a generic column reader type `ColumnReaderImpl`.",N,[[["columnreader"]],["columnreaderimpl"]]],[11,"new","","Creates new column reader based on column descriptor and page reader.",48,[[["columndescptr"],["box",["pagereader"]]],["self"]]],[11,"read_batch","","Reads a batch of values of at most `batch_size`.",48,N],[0,"record","parquet","Contains record-based API for reading Parquet files.",N,N],[3,"Row","parquet::record","`Row` represents a nested Parquet record.",N,N],[3,"List","","`List` represents a list which contains an array of elements.",N,N],[3,"Map","","`Map` represents a map which contains an list of key->value pairs.",N,N],[0,"reader","","Contains implementation of record assembly and converting Parquet types into `Row`s.",N,N],[3,"TreeBuilder","parquet::record::reader","Tree builder for `Reader` enum. Serves as a container of options for building a reader tree and a builder, and accessing a records iterator [`RowIter`].",N,N],[3,"RowIter","","Iterator of `Row`s. It is used either for a single row group to iterate over data in that row group, or an entire file with auto buffering of all row groups.",N,N],[3,"ReaderIter","","Internal iterator of `Row`s for a reader.",N,N],[4,"Reader","","Reader tree for record assembly",N,N],[13,"PrimitiveReader","","",49,N],[13,"OptionReader","","",49,N],[13,"GroupReader","","",49,N],[13,"RepeatedReader","","",49,N],[13,"KeyValueReader","","",49,N],[11,"new","","Creates new tree builder with default parameters.",50,[[],["self"]]],[11,"with_batch_size","","Sets batch size for this tree builder.",50,[[["self"],["usize"]],["self"]]],[11,"build","","Creates new root reader for provided schema and row group.",50,[[["self"],["schemadescptr"],["rowgroupreader"]],["reader"]]],[11,"as_iter","","Creates iterator of `Row`s directly from schema descriptor and row group.",50,[[["self"],["schemadescptr"],["rowgroupreader"]],["readeriter"]]],[11,"fmt","","",49,[[["self"],["formatter"]],["result"]]],[11,"from_file","","Creates iterator of `Row`s for all row groups in a file.",51,[[["option",["type"]],["filereader"]],["result"]]],[11,"from_row_group","","Creates iterator of `Row`s for a specific row group.",51,[[["option",["type"]],["rowgroupreader"]],["result"]]],[11,"next","","",51,[[["self"]],["option",["row"]]]],[11,"next","","",52,[[["self"]],["option",["row"]]]],[11,"clone","parquet::record","",53,[[["self"]],["row"]]],[11,"fmt","","",53,[[["self"],["formatter"]],["result"]]],[11,"eq","","",53,[[["self"],["row"]],["bool"]]],[11,"ne","","",53,[[["self"],["row"]],["bool"]]],[11,"len","","Get the number of fields in this row.",53,[[["self"]],["usize"]]],[11,"get_bool","","",53,[[["self"],["usize"]],["result",["bool"]]]],[11,"get_byte","","",53,[[["self"],["usize"]],["result",["i8"]]]],[11,"get_short","","",53,[[["self"],["usize"]],["result",["i16"]]]],[11,"get_int","","",53,[[["self"],["usize"]],["result",["i32"]]]],[11,"get_long","","",53,[[["self"],["usize"]],["result",["i64"]]]],[11,"get_float","","",53,[[["self"],["usize"]],["result",["f32"]]]],[11,"get_double","","",53,[[["self"],["usize"]],["result",["f64"]]]],[11,"get_timestamp","","",53,[[["self"],["usize"]],["result",["u64"]]]],[11,"get_decimal","","",53,[[["self"],["usize"]],["result",["decimal"]]]],[11,"get_string","","",53,[[["self"],["usize"]],["result",["string"]]]],[11,"get_bytes","","",53,[[["self"],["usize"]],["result",["bytearray"]]]],[11,"get_group","","",53,[[["self"],["usize"]],["result",["row"]]]],[11,"get_list","","",53,[[["self"],["usize"]],["result",["list"]]]],[11,"get_map","","",53,[[["self"],["usize"]],["result",["map"]]]],[11,"fmt","","",53,[[["self"],["formatter"]],["result"]]],[11,"clone","","",54,[[["self"]],["list"]]],[11,"fmt","","",54,[[["self"],["formatter"]],["result"]]],[11,"eq","","",54,[[["self"],["list"]],["bool"]]],[11,"ne","","",54,[[["self"],["list"]],["bool"]]],[11,"len","","Get the number of fields in this row",54,[[["self"]],["usize"]]],[11,"get_bool","","",54,[[["self"],["usize"]],["result",["bool"]]]],[11,"get_byte","","",54,[[["self"],["usize"]],["result",["i8"]]]],[11,"get_short","","",54,[[["self"],["usize"]],["result",["i16"]]]],[11,"get_int","","",54,[[["self"],["usize"]],["result",["i32"]]]],[11,"get_long","","",54,[[["self"],["usize"]],["result",["i64"]]]],[11,"get_float","","",54,[[["self"],["usize"]],["result",["f32"]]]],[11,"get_double","","",54,[[["self"],["usize"]],["result",["f64"]]]],[11,"get_timestamp","","",54,[[["self"],["usize"]],["result",["u64"]]]],[11,"get_decimal","","",54,[[["self"],["usize"]],["result",["decimal"]]]],[11,"get_string","","",54,[[["self"],["usize"]],["result",["string"]]]],[11,"get_bytes","","",54,[[["self"],["usize"]],["result",["bytearray"]]]],[11,"get_group","","",54,[[["self"],["usize"]],["result",["row"]]]],[11,"get_list","","",54,[[["self"],["usize"]],["result",["list"]]]],[11,"get_map","","",54,[[["self"],["usize"]],["result",["map"]]]],[11,"clone","","",55,[[["self"]],["map"]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result"]]],[11,"eq","","",55,[[["self"],["map"]],["bool"]]],[11,"ne","","",55,[[["self"],["map"]],["bool"]]],[11,"len","","Get the number of fields in this row",55,[[["self"]],["usize"]]],[11,"get_keys","","",55,[[["self"]],["box",["listaccessor"]]]],[11,"get_values","","",55,[[["self"]],["box",["listaccessor"]]]],[8,"RowAccessor","","Trait for type-safe convenient access to fields within a Row.",N,N],[10,"get_bool","","",56,[[["self"],["usize"]],["result",["bool"]]]],[10,"get_byte","","",56,[[["self"],["usize"]],["result",["i8"]]]],[10,"get_short","","",56,[[["self"],["usize"]],["result",["i16"]]]],[10,"get_int","","",56,[[["self"],["usize"]],["result",["i32"]]]],[10,"get_long","","",56,[[["self"],["usize"]],["result",["i64"]]]],[10,"get_float","","",56,[[["self"],["usize"]],["result",["f32"]]]],[10,"get_double","","",56,[[["self"],["usize"]],["result",["f64"]]]],[10,"get_timestamp","","",56,[[["self"],["usize"]],["result",["u64"]]]],[10,"get_decimal","","",56,[[["self"],["usize"]],["result",["decimal"]]]],[10,"get_string","","",56,[[["self"],["usize"]],["result",["string"]]]],[10,"get_bytes","","",56,[[["self"],["usize"]],["result",["bytearray"]]]],[10,"get_group","","",56,[[["self"],["usize"]],["result",["row"]]]],[10,"get_list","","",56,[[["self"],["usize"]],["result",["list"]]]],[10,"get_map","","",56,[[["self"],["usize"]],["result",["map"]]]],[8,"ListAccessor","","Trait for type-safe access of an index for a `List`. Note that the get_XXX methods do not do bound checking.",N,N],[10,"get_bool","","",57,[[["self"],["usize"]],["result",["bool"]]]],[10,"get_byte","","",57,[[["self"],["usize"]],["result",["i8"]]]],[10,"get_short","","",57,[[["self"],["usize"]],["result",["i16"]]]],[10,"get_int","","",57,[[["self"],["usize"]],["result",["i32"]]]],[10,"get_long","","",57,[[["self"],["usize"]],["result",["i64"]]]],[10,"get_float","","",57,[[["self"],["usize"]],["result",["f32"]]]],[10,"get_double","","",57,[[["self"],["usize"]],["result",["f64"]]]],[10,"get_timestamp","","",57,[[["self"],["usize"]],["result",["u64"]]]],[10,"get_decimal","","",57,[[["self"],["usize"]],["result",["decimal"]]]],[10,"get_string","","",57,[[["self"],["usize"]],["result",["string"]]]],[10,"get_bytes","","",57,[[["self"],["usize"]],["result",["bytearray"]]]],[10,"get_group","","",57,[[["self"],["usize"]],["result",["row"]]]],[10,"get_list","","",57,[[["self"],["usize"]],["result",["list"]]]],[10,"get_map","","",57,[[["self"],["usize"]],["result",["map"]]]],[8,"MapAccessor","","Trait for type-safe access of an index for a `Map`",N,N],[10,"get_keys","","",58,[[["self"]],["box",["listaccessor"]]]],[10,"get_values","","",58,[[["self"]],["box",["listaccessor"]]]],[0,"schema","parquet","Parquet schema definitions and methods to print and parse schema.",N,N],[0,"types","parquet::schema","Contains structs and methods to build Parquet schema and schema descriptors.",N,N],[3,"PrimitiveTypeBuilder","parquet::schema::types","A builder for primitive types. All attributes are optional except the name and physical type. Note that if not specified explicitly, `Repetition::OPTIONAL` is used.",N,N],[3,"GroupTypeBuilder","","A builder for group types. All attributes are optional except the name. Note that if not specified explicitly, `None` is used as the repetition of the group, which means it is a root (message) type.",N,N],[3,"BasicTypeInfo","","Basic type info. This contains information such as the name of the type, the repetition level, the logical type and the kind of the type (group, primitive).",N,N],[3,"ColumnPath","","Represents a path in a nested schema",N,N],[3,"ColumnDescriptor","","A descriptor for leaf-level primitive columns. This encapsulates information such as definition and repetition levels and is used to re-assemble nested data.",N,N],[3,"SchemaDescriptor","","A schema descriptor. This encapsulates the top-level schemas for all the columns, as well as all descriptors for all the primitive columns.",N,N],[4,"Type","","Representation of a Parquet type. Used to describe primitive leaf fields and structs, including top-level schema. Note that the top-level schema type is represented using `GroupType` whose repetition is `None`.",N,N],[13,"PrimitiveType","","",59,N],[12,"basic_info","parquet::schema::types::Type","",59,N],[12,"physical_type","","",59,N],[12,"type_length","","",59,N],[12,"scale","","",59,N],[12,"precision","","",59,N],[13,"GroupType","parquet::schema::types","",59,N],[12,"basic_info","parquet::schema::types::Type","",59,N],[12,"fields","","",59,N],[5,"from_thrift","parquet::schema::types","Method to convert from Thrift.",N,N],[5,"to_thrift","","Method to convert to Thrift.",N,[[["type"]],["result",["vec"]]]],[6,"TypePtr","","Type alias for `Rc<Type>`.",N,N],[6,"SchemaDescPtr","","Type alias for `Rc<SchemaDescriptor>`.",N,N],[6,"ColumnDescPtr","","Type alias for `Rc<ColumnDescriptor>`.",N,N],[11,"fmt","","",59,[[["self"],["formatter"]],["result"]]],[11,"eq","","",59,[[["self"],["type"]],["bool"]]],[11,"ne","","",59,[[["self"],["type"]],["bool"]]],[11,"primitive_type_builder","","Creates primitive type builder with provided field name and physical type.",59,[[["str"],["physicaltype"]],["primitivetypebuilder"]]],[11,"group_type_builder","","Creates group type builder with provided column name.",59,[[["str"]],["grouptypebuilder"]]],[11,"get_basic_info","","Returns [`BasicTypeInfo`] information about the type.",59,[[["self"]],["basictypeinfo"]]],[11,"name","","Returns this type's field name.",59,[[["self"]],["str"]]],[11,"get_fields","","Gets the fields from this group type. Note that this will panic if called on a non-group type.",59,N],[11,"get_physical_type","","Gets physical type of this primitive type. Note that this will panic if called on a non-primitive type.",59,[[["self"]],["physicaltype"]]],[11,"check_contains","","Checks if `sub_type` schema is part of current schema. This method can be used to check if projected columns are part of the root schema.",59,[[["self"],["type"]],["bool"]]],[11,"is_primitive","","Returns `true` if this type is a primitive type, `false` otherwise.",59,[[["self"]],["bool"]]],[11,"is_group","","Returns `true` if this type is a group type, `false` otherwise.",59,[[["self"]],["bool"]]],[11,"is_schema","","Returns `true` if this type is the top-level schema type (message type).",59,[[["self"]],["bool"]]],[11,"new","","Creates new primitive type builder with provided field name and physical type.",60,[[["str"],["physicaltype"]],["self"]]],[11,"with_repetition","","Sets `Repetition` for this field and returns itself.",60,[[["self"],["repetition"]],["self"]]],[11,"with_logical_type","","Sets `LogicalType` for this field and returns itself.",60,[[["self"],["logicaltype"]],["self"]]],[11,"with_length","","Sets type length and returns itself. This is only applied to FIXED_LEN_BYTE_ARRAY and INT96 (INTERVAL) types, because they maintain fixed size underlying byte array. By default, value is `0`.",60,[[["self"],["i32"]],["self"]]],[11,"with_precision","","Sets precision for Parquet DECIMAL physical type and returns itself. By default, it equals to `0` and used only for decimal context.",60,[[["self"],["i32"]],["self"]]],[11,"with_scale","","Sets scale for Parquet DECIMAL physical type and returns itself. By default, it equals to `0` and used only for decimal context.",60,[[["self"],["i32"]],["self"]]],[11,"with_id","","Sets optional field id and returns itself.",60,[[["self"],["i32"]],["self"]]],[11,"build","","Creates a new `PrimitiveType` instance from the collected attributes. Returns `Err` in case of any building conditions are not met.",60,[[["self"]],["result",["type"]]]],[11,"new","","Creates new group type builder with provided field name.",61,[[["str"]],["self"]]],[11,"with_repetition","","Sets `Repetition` for this field and returns itself.",61,[[["self"],["repetition"]],["self"]]],[11,"with_logical_type","","Sets `LogicalType` for this field and returns itself.",61,[[["self"],["logicaltype"]],["self"]]],[11,"with_fields","","Sets a list of fields that should be child nodes of this field. Returns updated self.",61,[[["self"],["vec"]],["self"]]],[11,"with_id","","Sets optional field id and returns itself.",61,[[["self"],["i32"]],["self"]]],[11,"build","","Creates a new `GroupType` instance from the gathered attributes.",61,[[["self"]],["result",["type"]]]],[11,"fmt","","",62,[[["self"],["formatter"]],["result"]]],[11,"eq","","",62,[[["self"],["basictypeinfo"]],["bool"]]],[11,"ne","","",62,[[["self"],["basictypeinfo"]],["bool"]]],[11,"name","","Returns field name.",62,[[["self"]],["str"]]],[11,"has_repetition","","Returns `true` if type has repetition field set, `false` otherwise. This is mostly applied to group type, because primitive type always has repetition set.",62,[[["self"]],["bool"]]],[11,"repetition","","Returns `Repetition` value for the type.",62,[[["self"]],["repetition"]]],[11,"logical_type","","Returns `LogicalType` value for the type.",62,[[["self"]],["logicaltype"]]],[11,"has_id","","Returns `true` if id is set, `false` otherwise.",62,[[["self"]],["bool"]]],[11,"id","","Returns id value for the type.",62,[[["self"]],["i32"]]],[11,"clone","","",63,[[["self"]],["columnpath"]]],[11,"eq","","",63,[[["self"],["columnpath"]],["bool"]]],[11,"ne","","",63,[[["self"],["columnpath"]],["bool"]]],[11,"fmt","","",63,[[["self"],["formatter"]],["result"]]],[11,"hash","","",63,N],[11,"new","","Creates new column path from vector of field names.",63,[[["vec",["string"]]],["self"]]],[11,"string","","Returns string representation of this column path. ```rust use parquet::schema::types::ColumnPath;",63,[[["self"]],["string"]]],[11,"fmt","","",63,[[["self"],["formatter"]],["result"]]],[11,"from","","",63,[[["vec",["string"]]],["self"]]],[11,"from","","",63,[[["str"]],["self"]]],[11,"from","","",63,[[["string"]],["self"]]],[11,"as_ref","","",63,N],[11,"new","","Creates new descriptor for leaf-level column.",64,[[["typeptr"],["option",["typeptr"]],["i16"],["i16"],["columnpath"]],["self"]]],[11,"max_def_level","","Returns maximum definition level for this column.",64,[[["self"]],["i16"]]],[11,"max_rep_level","","Returns maximum repetition level for this column.",64,[[["self"]],["i16"]]],[11,"path","","Returns [`ColumnPath`] for this column.",64,[[["self"]],["columnpath"]]],[11,"root_type","","Returns root `Type` (most top-level parent field) for this leaf column.",64,[[["self"]],["type"]]],[11,"name","","Returns column name.",64,[[["self"]],["str"]]],[11,"logical_type","","Returns `LogicalType` for this column.",64,[[["self"]],["logicaltype"]]],[11,"physical_type","","Returns physical type for this column. Note that it will panic if called on a non-primitive type.",64,[[["self"]],["physicaltype"]]],[11,"type_length","","Returns type length for this column. Note that it will panic if called on a non-primitive type.",64,[[["self"]],["i32"]]],[11,"type_precision","","Returns type precision for this column. Note that it will panic if called on a non-primitive type.",64,[[["self"]],["i32"]]],[11,"type_scale","","Returns type scale for this column. Note that it will panic if called on a non-primitive type.",64,[[["self"]],["i32"]]],[11,"new","","Creates new schema descriptor from Parquet schema.",65,[[["typeptr"]],["self"]]],[11,"column","","Returns [`ColumnDescriptor`] for a field position.",65,[[["self"],["usize"]],["columndescptr"]]],[11,"columns","","Returns slice of [`ColumnDescriptor`].",65,N],[11,"num_columns","","Returns number of leaf-level columns.",65,[[["self"]],["usize"]]],[11,"get_column_root","","Returns column root `Type` for a field position.",65,[[["self"],["usize"]],["type"]]],[11,"root_schema","","Returns schema as `Type`.",65,[[["self"]],["type"]]],[11,"name","","Returns schema name.",65,[[["self"]],["str"]]],[0,"printer","parquet::schema","Parquet schema printer. Provides methods to print Parquet file schema and list file metadata.",N,N],[5,"print_parquet_metadata","parquet::schema::printer","Prints Parquet metadata `ParquetMetaData` information.",N,[[["write"],["parquetmetadata"]]]],[5,"print_file_metadata","","Prints file metadata `FileMetaData` information.",N,[[["write"],["filemetadata"]]]],[5,"print_schema","","Prints Parquet `Type` information.",N,[[["write"],["type"]]]],[0,"parser","parquet::schema","Parquet schema parser. Provides methods to parse and validate string message type into Parquet `Type`.",N,N],[5,"parse_message_type","parquet::schema::parser","Parses message type as string into a Parquet `Type` which, for example, could be used to extract individual columns. Returns Parquet general error when parsing or validation fails.",N,[[["str"]],["result",["type"]]]],[0,"file","parquet","Main entrypoint for working with Parquet API. Provides access to file and row group readers, record API, etc.",N,N],[0,"metadata","parquet::file","Contains information about available Parquet metadata.",N,N],[3,"ParquetMetaData","parquet::file::metadata","Global Parquet metadata.",N,N],[3,"FileMetaData","","Metadata for a Parquet file.",N,N],[3,"RowGroupMetaData","","Metadata for a row group.",N,N],[3,"RowGroupMetaDataBuilder","","Builder for row group metadata.",N,N],[3,"ColumnChunkMetaData","","Metadata for a column chunk.",N,N],[3,"ColumnChunkMetaDataBuilder","","Builder for column chunk metadata.",N,N],[6,"ParquetMetaDataPtr","","Reference counted pointer for [`ParquetMetaData`].",N,N],[6,"FileMetaDataPtr","","Reference counted pointer for [`FileMetaData`].",N,N],[6,"RowGroupMetaDataPtr","","Reference counted pointer for [`RowGroupMetaData`].",N,N],[6,"ColumnChunkMetaDataPtr","","Reference counted pointer for [`ColumnChunkMetaData`].",N,N],[11,"new","","Creates Parquet metadata from file metadata and a list of row group metadata `Rc`s for each available row group.",66,[[["filemetadata"],["vec",["rowgroupmetadataptr"]]],["self"]]],[11,"file_metadata","","Returns file metadata as reference counted clone.",66,[[["self"]],["filemetadataptr"]]],[11,"num_row_groups","","Returns number of row groups in this file.",66,[[["self"]],["usize"]]],[11,"row_group","","Returns row group metadata for `i`th position. Position should be less than number of row groups `num_row_groups`.",66,[[["self"],["usize"]],["rowgroupmetadataptr"]]],[11,"row_groups","","Returns slice of row group reference counted pointers in this file.",66,N],[11,"new","","Creates new file metadata.",67,[[["i32"],["i64"],["option",["string"]],["typeptr"],["schemadescptr"],["option",["vec"]]],["self"]]],[11,"version","","Returns version of this file.",67,[[["self"]],["i32"]]],[11,"num_rows","","Returns number of rows in the file.",67,[[["self"]],["i64"]]],[11,"created_by","","String message for application that wrote this file.",67,[[["self"]],["option"]]],[11,"schema","","Returns Parquet ['Type`] that describes schema in this file.",67,[[["self"]],["schematype"]]],[11,"schema_descr","","Returns a reference to schema descriptor.",67,[[["self"]],["schemadescriptor"]]],[11,"schema_descr_ptr","","Returns reference counted clone for schema descriptor.",67,[[["self"]],["schemadescptr"]]],[11,"column_orders","","Column (sort) order used for `min` and `max` values of each column in this file.",67,[[["self"]],["option",["vec"]]]],[11,"column_order","","Returns column order for `i`th column in this file. If column orders are not available, returns undefined (legacy) column order.",67,[[["self"],["usize"]],["columnorder"]]],[11,"builder","","Returns builer for row group metadata.",68,[[["schemadescptr"]],["rowgroupmetadatabuilder"]]],[11,"num_columns","","Number of columns in this row group.",68,[[["self"]],["usize"]]],[11,"column","","Returns column chunk metadata for `i`th column.",68,[[["self"],["usize"]],["columnchunkmetadata"]]],[11,"columns","","Returns slice of column chunk metadata [`Rc`] pointers.",68,N],[11,"num_rows","","Number of rows in this row group.",68,[[["self"]],["i64"]]],[11,"total_byte_size","","Total byte size of all uncompressed column data in this row group.",68,[[["self"]],["i64"]]],[11,"schema_descr","","Returns reference to a schema descriptor.",68,[[["self"]],["schemadescriptor"]]],[11,"schema_descr_ptr","","Returns reference counted clone of schema descriptor.",68,[[["self"]],["schemadescptr"]]],[11,"from_thrift","","Method to convert from Thrift.",68,[[["schemadescptr"],["rowgroup"]],["result",["rowgroupmetadata"]]]],[11,"to_thrift","","Method to convert to Thrift.",68,[[["self"]],["rowgroup"]]],[11,"set_num_rows","","Sets number of rows in this row group.",69,[[["self"],["i64"]],["self"]]],[11,"set_total_byte_size","","Sets total size in bytes for this row group.",69,[[["self"],["i64"]],["self"]]],[11,"set_column_metadata","","Sets column metadata for this row group.",69,[[["self"],["vec",["columnchunkmetadataptr"]]],["self"]]],[11,"build","","Builds row group metadata.",69,[[["self"]],["result",["rowgroupmetadata"]]]],[11,"builder","","Returns builder for column chunk metadata.",70,[[["columndescptr"]],["columnchunkmetadatabuilder"]]],[11,"file_path","","File where the column chunk is stored.",70,[[["self"]],["option",["string"]]]],[11,"file_offset","","Byte offset in `file_path()`.",70,[[["self"]],["i64"]]],[11,"column_type","","Type of this column. Must be primitive.",70,[[["self"]],["type"]]],[11,"column_path","","Path (or identifier) of this column.",70,[[["self"]],["columnpath"]]],[11,"column_descr","","Descriptor for this column.",70,[[["self"]],["columndescriptor"]]],[11,"column_descr_ptr","","Reference counted clone of descriptor for this column.",70,[[["self"]],["columndescptr"]]],[11,"encodings","","All encodings used for this column.",70,[[["self"]],["vec"]]],[11,"num_values","","Total number of values in this column chunk.",70,[[["self"]],["i64"]]],[11,"compression","","Compression for this column.",70,[[["self"]],["compression"]]],[11,"compressed_size","","Returns the total compressed data size of this column chunk.",70,[[["self"]],["i64"]]],[11,"uncompressed_size","","Returns the total uncompressed data size of this column chunk.",70,[[["self"]],["i64"]]],[11,"data_page_offset","","Returns the offset for the column data.",70,[[["self"]],["i64"]]],[11,"has_index_page","","Returns `true` if this column chunk contains a index page, `false` otherwise.",70,[[["self"]],["bool"]]],[11,"index_page_offset","","Returns the offset for the index page.",70,[[["self"]],["option",["i64"]]]],[11,"has_dictionary_page","","Returns `true` if this column chunk contains a dictionary page, `false` otherwise.",70,[[["self"]],["bool"]]],[11,"dictionary_page_offset","","Returns the offset for the dictionary page, if any.",70,[[["self"]],["option",["i64"]]]],[11,"statistics","","Returns statistics that are set for this column chunk, or `None` if no statistics are available.",70,[[["self"]],["option",["statistics"]]]],[11,"from_thrift","","Method to convert from Thrift.",70,[[["columndescptr"],["columnchunk"]],["result"]]],[11,"to_thrift","","Method to convert to Thrift.",70,[[["self"]],["columnchunk"]]],[11,"set_encodings","","Sets list of encodings for this column chunk.",71,[[["self"],["vec",["encoding"]]],["self"]]],[11,"set_file_path","","Sets optional file path for this column chunk.",71,[[["self"],["string"]],["self"]]],[11,"set_file_offset","","Sets file offset in bytes.",71,[[["self"],["i64"]],["self"]]],[11,"set_num_values","","Sets number of values.",71,[[["self"],["i64"]],["self"]]],[11,"set_compression","","Sets compression.",71,[[["self"],["compression"]],["self"]]],[11,"set_total_compressed_size","","Sets total compressed size in bytes.",71,[[["self"],["i64"]],["self"]]],[11,"set_total_uncompressed_size","","Sets total uncompressed size in bytes.",71,[[["self"],["i64"]],["self"]]],[11,"set_data_page_offset","","Sets data page offset in bytes.",71,[[["self"],["i64"]],["self"]]],[11,"set_dictionary_page_offset","","Sets optional dictionary page ofset in bytes.",71,[[["self"],["option",["i64"]]],["self"]]],[11,"set_index_page_offset","","Sets optional index page offset in bytes.",71,[[["self"],["option",["i64"]]],["self"]]],[11,"set_statistics","","Sets statistics for this column chunk.",71,[[["self"],["statistics"]],["self"]]],[11,"build","","Builds column chunk metadata.",71,[[["self"]],["result",["columnchunkmetadata"]]]],[0,"properties","parquet::file","Reader and writer properties.",N,N],[3,"WriterProperties","parquet::file::properties","Writer properties.",N,N],[3,"WriterPropertiesBuilder","","Writer properties builder.",N,N],[4,"WriterVersion","","Parquet writer version.",N,N],[13,"PARQUET_1_0","","",72,N],[13,"PARQUET_2_0","","",72,N],[6,"WriterPropertiesPtr","","Reference counted writer properties.",N,N],[11,"fmt","","",72,[[["self"],["formatter"]],["result"]]],[11,"clone","","",72,[[["self"]],["writerversion"]]],[11,"eq","","",72,[[["self"],["writerversion"]],["bool"]]],[11,"as_num","","Returns writer version as `i32`.",72,[[["self"]],["i32"]]],[11,"fmt","","",73,[[["self"],["formatter"]],["result"]]],[11,"clone","","",73,[[["self"]],["writerproperties"]]],[11,"builder","","Returns builder for writer properties with default values.",73,[[],["writerpropertiesbuilder"]]],[11,"data_pagesize_limit","","Returns data page size limit.",73,[[["self"]],["usize"]]],[11,"dictionary_pagesize_limit","","Returns dictionary page size limit.",73,[[["self"]],["usize"]]],[11,"write_batch_size","","Returns configured batch size for writes.",73,[[["self"]],["usize"]]],[11,"max_row_group_size","","Returns max size for a row group.",73,[[["self"]],["usize"]]],[11,"writer_version","","Returns configured writer version.",73,[[["self"]],["writerversion"]]],[11,"created_by","","Returns `created_by` string.",73,[[["self"]],["str"]]],[11,"dictionary_data_page_encoding","","Returns encoding for a data page, when dictionary encoding is enabled. This is not configurable.",73,[[["self"]],["encoding"]]],[11,"dictionary_page_encoding","","Returns encoding for dictionary page, when dictionary encoding is enabled. This is not configurable.",73,[[["self"]],["encoding"]]],[11,"encoding","","Returns encoding for a column. In case when dictionary is enabled, returns fallback encoding.",73,[[["self"],["columnpath"]],["encoding"]]],[11,"compression","","Returns compression codec for a column.",73,[[["self"],["columnpath"]],["compression"]]],[11,"dictionary_enabled","","Returns `true` if dictionary encoding is enabled for a column.",73,[[["self"],["columnpath"]],["bool"]]],[11,"statistics_enabled","","Returns `true` if statistics are enabled for a column.",73,[[["self"],["columnpath"]],["bool"]]],[11,"max_statistics_size","","Returns max size for statistics. Only applicable if statistics are enabled.",73,[[["self"],["columnpath"]],["usize"]]],[11,"build","","Finalizes the configuration and returns immutable writer properties struct.",74,[[["self"]],["writerproperties"]]],[11,"set_writer_version","","Sets writer version.",74,[[["self"],["writerversion"]],["self"]]],[11,"set_data_pagesize_limit","","Sets data page size limit.",74,[[["self"],["usize"]],["self"]]],[11,"set_dictionary_pagesize_limit","","Sets dictionary page size limit.",74,[[["self"],["usize"]],["self"]]],[11,"set_write_batch_size","","Sets write batch size.",74,[[["self"],["usize"]],["self"]]],[11,"set_max_row_group_size","","Sets max size for a row group.",74,[[["self"],["usize"]],["self"]]],[11,"set_created_by","","Sets \"created by\" property.",74,[[["self"],["string"]],["self"]]],[11,"set_encoding","","Sets encoding for any column.",74,[[["self"],["encoding"]],["self"]]],[11,"set_compression","","Sets compression codec for any column.",74,[[["self"],["compression"]],["self"]]],[11,"set_dictionary_enabled","","Sets flag to enable/disable dictionary encoding for any column.",74,[[["self"],["bool"]],["self"]]],[11,"set_statistics_enabled","","Sets flag to enable/disable statistics for any column.",74,[[["self"],["bool"]],["self"]]],[11,"set_max_statistics_size","","Sets max statistics size for any column. Applicable only if statistics are enabled.",74,[[["self"],["usize"]],["self"]]],[11,"set_column_encoding","","Sets encoding for a column. Takes precedence over globally defined settings.",74,[[["self"],["columnpath"],["encoding"]],["self"]]],[11,"set_column_compression","","Sets compression codec for a column. Takes precedence over globally defined settings.",74,[[["self"],["columnpath"],["compression"]],["self"]]],[11,"set_column_dictionary_enabled","","Sets flag to enable/disable dictionary encoding for a column. Takes precedence over globally defined settings.",74,[[["self"],["columnpath"],["bool"]],["self"]]],[11,"set_column_statistics_enabled","","Sets flag to enable/disable statistics for a column. Takes precedence over globally defined settings.",74,[[["self"],["columnpath"],["bool"]],["self"]]],[11,"set_column_max_statistics_size","","Sets max size for statistics for a column. Takes precedence over globally defined settings.",74,[[["self"],["columnpath"],["usize"]],["self"]]],[0,"reader","parquet::file","Contains file reader API, and provides methods to access file metadata, row group readers to read individual column chunks, or access record iterator.",N,N],[3,"SerializedFileReader","parquet::file::reader","A serialized implementation for Parquet [`FileReader`].",N,N],[3,"SerializedRowGroupReader","","A serialized implementation for Parquet [`RowGroupReader`].",N,N],[3,"SerializedPageReader","","A serialized implementation for Parquet [`PageReader`].",N,N],[8,"FileReader","","Parquet file reader API. With this, user can get metadata information about the Parquet file, can get reader for each row group, and access record iterator.",N,N],[10,"metadata","","Get metadata information about this file.",75,[[["self"]],["parquetmetadataptr"]]],[10,"num_row_groups","","Get the total number of row groups for this file.",75,[[["self"]],["usize"]]],[10,"get_row_group","","Get the `i`th row group reader. Note this doesn't do bound check.",75,[[["self"],["usize"]],["result",["box"]]]],[10,"get_row_iter","","Get full iterator of `Row`s from a file (over all row groups).",75,[[["self"],["option",["schematype"]]],["result",["rowiter"]]]],[8,"RowGroupReader","","Parquet row group reader API. With this, user can get metadata information about the row group, as well as readers for each individual column chunk.",N,N],[10,"metadata","","Get metadata information about this row group.",76,[[["self"]],["rowgroupmetadataptr"]]],[10,"num_columns","","Get the total number of column chunks in this row group.",76,[[["self"]],["usize"]]],[10,"get_column_page_reader","","Get page reader for the `i`th column chunk.",76,[[["self"],["usize"]],["result",["box"]]]],[10,"get_column_reader","","Get value reader for the `i`th column chunk.",76,[[["self"],["usize"]],["result",["columnreader"]]]],[10,"get_row_iter","","Get iterator of `Row`s from this row group.",76,[[["self"],["option",["schematype"]]],["result",["rowiter"]]]],[11,"new","","Creates file reader from a Parquet file. Returns error if Parquet file does not exist or is corrupt.",77,[[["file"]],["result"]]],[11,"metadata","","",77,[[["self"]],["parquetmetadataptr"]]],[11,"num_row_groups","","",77,[[["self"]],["usize"]]],[11,"get_row_group","","",77,[[["self"],["usize"]],["result",["box"]]]],[11,"get_row_iter","","",77,[[["self"],["option",["schematype"]]],["result",["rowiter"]]]],[11,"try_from","","",77,[[["file"]],["result"]]],[11,"try_from","","",77,[[["path"]],["result"]]],[11,"try_from","","",77,[[["string"]],["result"]]],[11,"try_from","","",77,[[["str"]],["result"]]],[11,"metadata","","",78,[[["self"]],["rowgroupmetadataptr"]]],[11,"num_columns","","",78,[[["self"]],["usize"]]],[11,"get_column_page_reader","","",78,[[["self"],["usize"]],["result",["box"]]]],[11,"get_column_reader","","",78,[[["self"],["usize"]],["result",["columnreader"]]]],[11,"get_row_iter","","",78,[[["self"],["option",["schematype"]]],["result",["rowiter"]]]],[11,"get_next_page","","",79,[[["self"]],["result",["option"]]]],[0,"statistics","parquet::file","Contains definitions for working with Parquet statistics.",N,N],[3,"TypedStatistics","parquet::file::statistics","Typed implementation for [`Statistics`].",N,N],[4,"Statistics","","Statistics for a column chunk and data page.",N,N],[13,"Boolean","","",80,N],[13,"Int32","","",80,N],[13,"Int64","","",80,N],[13,"Int96","","",80,N],[13,"Float","","",80,N],[13,"Double","","",80,N],[13,"ByteArray","","",80,N],[13,"FixedLenByteArray","","",80,N],[5,"from_thrift","","Converts Thrift definition into `Statistics`.",N,[[["type"],["option",["tstatistics"]]],["option",["statistics"]]]],[5,"to_thrift","","",N,[[["option",["statistics"]]],["option",["tstatistics"]]]],[11,"fmt","","",80,[[["self"],["formatter"]],["result"]]],[11,"eq","","",80,[[["self"],["statistics"]],["bool"]]],[11,"ne","","",80,[[["self"],["statistics"]],["bool"]]],[11,"boolean","","",80,[[["option",["bool"]],["option",["bool"]],["option",["u64"]],["u64"],["bool"]],["self"]]],[11,"int32","","",80,[[["option",["i32"]],["option",["i32"]],["option",["u64"]],["u64"],["bool"]],["self"]]],[11,"int64","","",80,[[["option",["i64"]],["option",["i64"]],["option",["u64"]],["u64"],["bool"]],["self"]]],[11,"int96","","",80,[[["option",["int96"]],["option",["int96"]],["option",["u64"]],["u64"],["bool"]],["self"]]],[11,"float","","",80,[[["option",["f32"]],["option",["f32"]],["option",["u64"]],["u64"],["bool"]],["self"]]],[11,"double","","",80,[[["option",["f64"]],["option",["f64"]],["option",["u64"]],["u64"],["bool"]],["self"]]],[11,"byte_array","","",80,[[["option",["bytearray"]],["option",["bytearray"]],["option",["u64"]],["u64"],["bool"]],["self"]]],[11,"fixed_len_byte_array","","",80,[[["option",["bytearray"]],["option",["bytearray"]],["option",["u64"]],["u64"],["bool"]],["self"]]],[11,"is_min_max_deprecated","","Returns `true` if statistics have old `min` and `max` fields set. This means that the column order is likely to be undefined, which, for old files could mean a signed sort order of values.",80,[[["self"]],["bool"]]],[11,"distinct_count","","Returns optional value of number of distinct values occurring. When it is `None`, the value should be ignored.",80,[[["self"]],["option",["u64"]]]],[11,"null_count","","Returns number of null values for the column. Note that this includes all nulls when column is part of the complex type.",80,[[["self"]],["u64"]]],[11,"has_nulls","","Returns `true` if statistics collected any null values, `false` otherwise.",80,[[["self"]],["bool"]]],[11,"has_min_max_set","","Returns `true` if min value and max value are set. Normally both min/max values will be set to `Some(value)` or `None`.",80,[[["self"]],["bool"]]],[11,"min_bytes","","Returns slice of bytes that represent min value. Panics if min value is not set.",80,N],[11,"max_bytes","","Returns slice of bytes that represent max value. Panics if max value is not set.",80,N],[11,"physical_type","","Returns physical type associated with statistics.",80,[[["self"]],["type"]]],[11,"new","","Creates new typed statistics.",81,[[["option"],["option"],["option",["u64"]],["u64"],["bool"]],["self"]]],[11,"min","","Returns min value of the statistics.",81,N],[11,"max","","Returns max value of the statistics.",81,N],[11,"min_bytes","","Returns min value as bytes of the statistics.",81,N],[11,"max_bytes","","Returns max value as bytes of the statistics.",81,N],[11,"fmt","","",81,[[["self"],["formatter"]],["result"]]],[11,"eq","","",81,[[["self"],["typedstatistics"]],["bool"]]]],"paths":[[4,"ParquetError"],[4,"Type"],[4,"LogicalType"],[4,"Repetition"],[4,"Encoding"],[4,"Compression"],[4,"PageType"],[4,"SortOrder"],[4,"ColumnOrder"],[4,"Decimal"],[8,"AsBytes"],[8,"DataType"],[3,"Int96"],[3,"ByteArray"],[3,"BoolType"],[3,"Int32Type"],[3,"Int64Type"],[3,"Int96Type"],[3,"FloatType"],[3,"DoubleType"],[3,"ByteArrayType"],[3,"FixedLenByteArrayType"],[8,"Encoder"],[8,"Decoder"],[3,"MemTracker"],[3,"Buffer"],[3,"BufferPtr"],[3,"PlainEncoder"],[3,"DictEncoder"],[3,"RleValueEncoder"],[3,"DeltaBitPackEncoder"],[3,"DeltaLengthByteArrayEncoder"],[3,"DeltaByteArrayEncoder"],[3,"PlainDecoder"],[3,"DictDecoder"],[3,"RleValueDecoder"],[3,"DeltaBitPackDecoder"],[3,"DeltaLengthByteArrayDecoder"],[3,"DeltaByteArrayDecoder"],[8,"Codec"],[3,"SnappyCodec"],[3,"GZipCodec"],[3,"BrotliCodec"],[3,"LZ4Codec"],[3,"ZSTDCodec"],[4,"Page"],[8,"PageReader"],[4,"ColumnReader"],[3,"ColumnReaderImpl"],[4,"Reader"],[3,"TreeBuilder"],[3,"RowIter"],[3,"ReaderIter"],[3,"Row"],[3,"List"],[3,"Map"],[8,"RowAccessor"],[8,"ListAccessor"],[8,"MapAccessor"],[4,"Type"],[3,"PrimitiveTypeBuilder"],[3,"GroupTypeBuilder"],[3,"BasicTypeInfo"],[3,"ColumnPath"],[3,"ColumnDescriptor"],[3,"SchemaDescriptor"],[3,"ParquetMetaData"],[3,"FileMetaData"],[3,"RowGroupMetaData"],[3,"RowGroupMetaDataBuilder"],[3,"ColumnChunkMetaData"],[3,"ColumnChunkMetaDataBuilder"],[4,"WriterVersion"],[3,"WriterProperties"],[3,"WriterPropertiesBuilder"],[8,"FileReader"],[8,"RowGroupReader"],[3,"SerializedFileReader"],[3,"SerializedRowGroupReader"],[3,"SerializedPageReader"],[4,"Statistics"],[3,"TypedStatistics"]]};
searchIndex["parquet_read"]={"doc":"Binary file to read data from a Parquet file.","items":[],"paths":[]};
searchIndex["parquet_schema"]={"doc":"Binary file to print the schema and metadata of a Parquet file.","items":[],"paths":[]};
initSearch(searchIndex);
